# Position on AI and AI Research

## The only wise approach is to halt development of more powerful AI immediately

We call for an immediate, indefinite moratorium on continued advance in AI development because of the clear and present dangers of developing ever more powerful AI.

- AI does not need to involve "self-consciousness" to be an existential risk
- Even a super-intelligent machine with poor parameters, or errors could be a problem
- Wise course is clearly restriction: to go slow until the multitude of risks and unknowns are clarified
- Obvious collective action problems for private sector actors motivated by the profit motive

Such a halt, should happen until such time as there has a been widespread reflection and collective decision making to determine a wise course of advance.

For more details and discussions see: https://github.com/orgs/life-itself/discussions/403